output:
  html_document:
    fig_height: 10
    fig_width: 12
    highlight: zenburn
    number_sections: yes
    theme: lumen
    toc: true


{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment=NA, message=FALSE, warning=FALSE)


{r, message=FALSE, warning=FALSE, include=FALSE}
library(plyr)
library(dplyr, pos = "package:base")
library(knitr)

libs <- c("ggplot2", "plotly", "reshape2", "magrittr", "ggthemes", "tidyr", "DT", "lubridate", "stringr", "RColorBrewer", "readr", "grid", "gridExtra", "intubate", "highcharter", "ggfortify")
lapply(libs, require, character.only = TRUE)

ml.libs <- c("rpart", "rpart.plot", "party", "rattle", "partykit", "caret", "randomForest", "xgboost", "rpart.plot", "FFTrees", "mlbench", "caretEnsemble", "nnet", "e1071", "kernlab")
lapply(ml.libs, require, character.only = TRUE)

ml.libs.add <- c("class", "fastknn", "caTools", "glmnet", "h2o", "ipred", "ade4", "ROCR", "pROC", "Boruta", "NeuralNetTools")
lapply(ml.libs.add, require, character.only = TRUE)


library(ellipse)


{r echo = FALSE}
glass <- read.csv('../input/glass.csv', stringsAsFactors = FALSE)


{r echo = FALSE}
data <- sample(2, nrow(glass), replace = T, prob = c(0.7, 0.3))
train <- glass[data == 1,]
test <- glass[data == 2,]




{r echo = FALSE}


pca <- function(eData, printDropped = TRUE, scale = TRUE, center = TRUE) 
{
    if (class(eData) == "ExpressionSet") {
        annotationData <- annotation(eData)
        phenoData <- phenoData(eData)
        exprsData <- exprs(eData)
        expressionData <- list(annotationData, phenoData)
    }
    else {
        exprsData <- as.matrix(eData)
        expressionData <- NA
    }
    for (i in 1:length(exprsData[, 1])) {
        if (var(exprsData[i, ]) == 0) {
            exprsData[i, ] <- NA
            if (printDropped) {
                print(paste("Dropped variable", rownames(exprsData)[i], 
                  "because scaling is not possible (all values are equal)"))
            }
        }
    }
    exprsData <- na.omit(exprsData)
    p <- prcomp(t(exprsData), scale = scale, center = center)
    res <- list(scores = p$x, loadings = p$rotation, pov = p$sdev^2/sum(p$sdev^2), 
        expressionData = expressionData)
    class(res) <- "pca"
    res
}

pca_func <- function(data, groups, title, print_ellipse = TRUE) {
  
  # perform pca and extract scores
  pcaOutput <- pca(data, printDropped = FALSE, scale = TRUE, center = TRUE)
  pcaOutput2 <- as.data.frame(pcaOutput$scores)
  
  # define groups for plotting
  pcaOutput2$groups <- groups
  

  # when plotting samples calculate ellipses for plotting (when plotting features, there are no replicates)
  if (print_ellipse) {
    
    centroids <- aggregate(cbind(PC1, PC2) ~ groups, pcaOutput2, mean)
    conf.rgn  <- do.call(rbind, lapply(unique(pcaOutput2$groups), function(t)
      data.frame(groups = as.character(t),
                 ellipse(cov(pcaOutput2[pcaOutput2$groups == t, 1:2]),
                       centre = as.matrix(centroids[centroids$groups == t, 2:3]),
                       level = 0.95),
                 stringsAsFactors = FALSE)))
    
    plot <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
      geom_polygon(data = conf.rgn, aes(fill = groups), alpha = 0.2) +
      geom_point(size = 2, alpha = 0.6) + 
      scale_color_brewer(palette = "Set1") +
      labs(title = title,
           color = "",
           fill = "",
           x = paste0("PC1: ", round(pcaOutput$pov[1], digits = 2) * 100, "% variance"),
           y = paste0("PC2: ", round(pcaOutput$pov[2], digits = 2) * 100, "% variance"))
    
  } else {
    
    # if there are fewer than 10 groups (e.g. the predictor classes) I want to have colors from RColorBrewer
    if (length(unique(pcaOutput2$groups)) <= 10) {
      
      plot <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
        geom_point(size = 2, alpha = 0.6) + 
        scale_color_brewer(palette = "Set1") +
        labs(title = title,
             color = "",
             fill = "",
             x = paste0("PC1: ", round(pcaOutput$pov[1], digits = 2) * 100, "% variance"),
             y = paste0("PC2: ", round(pcaOutput$pov[2], digits = 2) * 100, "% variance"))
      
    } else {
      
      # otherwise use the default rainbow colors
      plot <- ggplot(data = pcaOutput2, aes(x = PC1, y = PC2, group = groups, color = groups)) + 
        geom_point(size = 2, alpha = 0.6) + 
        labs(title = title,
             color = "",
             fill = "",
             x = paste0("PC1: ", round(pcaOutput$pov[1], digits = 2) * 100, "% variance"),
             y = paste0("PC2: ", round(pcaOutput$pov[2], digits = 2) * 100, "% variance"))
      
    } 
  } 
  
  
  
  return(plot)
  
}

my_theme <- function(base_size = 12, base_family = "sans"){
  theme_minimal(base_size = base_size, base_family = base_family) +
  theme(
    axis.text = element_text(size = 12),
    axis.text.x = element_text(angle = 0, vjust = 0.5, hjust = 0.5),
    axis.title = element_text(size = 14),
    panel.grid.major = element_line(color = "grey"),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "aliceblue"),
    strip.background = element_rect(fill = "navy", color = "navy", size = 1),
    strip.text = element_text(face = "bold", size = 12, color = "white"),
    legend.position = "right",
    legend.justification = "top", 
    legend.background = element_blank(),
    panel.border = element_rect(color = "grey", fill = NA, size = 0.5)
  )
}

theme_set(my_theme())


dummy <- function(df) {  

    NUM <- function(dataframe)dataframe[,sapply(dataframe,is.numeric)]
    FAC <- function(dataframe)dataframe[,sapply(dataframe,is.factor)]

    require(ade4)
    if (is.null(ncol(NUM(df)))) {
        DF <- data.frame(NUM(df), acm.disjonctif(FAC(df)))
        names(DF)[1] <- colnames(df)[which(sapply(df, is.numeric))]
    } else {
        DF <- data.frame(NUM(df), acm.disjonctif(FAC(df)))
    }
    return(DF)
} 

feature_imp <- function(model, title) {
  
  # estimate variable importance
  importance <- varImp(model, scale = TRUE)
  
  # prepare dataframes for plotting
  importance_df_1 <- importance$importance
  importance_df_1$group <- rownames(importance_df_1)
  
  importance_df_2 <- importance_df_1
  importance_df_2$Overall <- 0
  
  importance_df <- rbind(importance_df_1, importance_df_2)
  importance_df %<>% arrange(desc(Overall))
  importance_df_1 %<>% arrange(desc(Overall))
  
  plot <- ggplot() +
    geom_point(data = importance_df_1, aes(x = Overall, y = group, color = group), size = 2) +
    geom_path(data = importance_df, aes(x = Overall, y = group, color = group, group = group), size = 1) +
    theme(legend.position = "none") +
    labs(
      x = "Importance",
      y = "",
      title = title,
      subtitle = "Scaled feature importance",
      caption = "\nDetermined with Random Forest and
      repeated cross validation (10 repeats, 10 times)"
    )
  
  return(plot)
  
}

{r echo=FALSE}
glass$Type %<>% as.character() 
temp <- glass
temp[,ncol(temp)][temp[,ncol(temp)] == "1"] <- "A"
temp[,ncol(temp)][temp[,ncol(temp)] == "2"] <- "B"
temp[,ncol(temp)][temp[,ncol(temp)] == "3"] <- "C"
temp[,ncol(temp)][temp[,ncol(temp)] == "5"] <- "D"
temp[,ncol(temp)][temp[,ncol(temp)] == "6"] <- "E"
temp[,ncol(temp)][temp[,ncol(temp)] == "7"] <- "F"
temp$Type %<>% as.factor()


glass_dum <- glass
glass_dum$Type_1 = "no"
glass_dum$Type_2 = "no"
glass_dum$Type_3 = "no"
glass_dum$Type_5 = "no"
glass_dum$Type_6 = "no"
glass_dum$Type_7 = "no"

for(i in 1:nrow(glass_dum)){
  if(glass_dum[i, "Type"] == "1")
    glass_dum$Type_1[i] <- "yes"
  else if(glass_dum[i, "Type"] == "2" ){
    glass_dum$Type_2[i] <- "yes"
  }
  else if(glass_dum[i, "Type"] == "3" ){
    glass_dum$Type_3[i] <- "yes"
  }
  else if(glass_dum[i, "Type"] == "5" ){
    glass_dum$Type_5[i] <- "yes"
  }
  else if(glass_dum[i, "Type"] == "6" ){
    glass_dum$Type_6[i] <- "yes"
  }
  else if(glass_dum[i, "Type"] == "7" ){
    glass_dum$Type_7[i] <- "yes"
  }
}

glass_dum %<>% select(-Type)




# Data Preview

Here is an observation of what the first 10 types of glass look like so we can get an idea for the dataset.

{r echo=FALSE}
glass %>% head(10) %>% kable()




# Exploratory Data Analysis

## Density Plot

Here we will observe where the majority of the data lies in the glass dataset as far as Type is concerned.
We can gather that the majority of the dataset lies with the glass type of 1 and the least with the glass type of 7.

{r echo=FALSE}
glass$Type %<>% as.factor() 
ggplot(glass, aes(x=Type))  +
  geom_density(aes(group = Type, fill = Type), alpha = 0.3) +
  theme(plot.subtitle = element_text(vjust = 1), 
    plot.caption = element_text(vjust = 1), 
    axis.text.x = element_text(angle = 90))+
    labs(title = "Glass: Types", 
    x = "Glass Type", y = "Density", colour = "Glass Types") +
        my_theme() +
        theme(axis.text.x = element_text(angle = 50),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())  +
        theme(legend.background = element_rect(size = 0.1), 
        legend.position = "top", legend.direction = "horizontal") +
        theme(plot.title = element_text(size = 18, hjust = 0.5)) 



***

# Machine Learning Aspects{.tabset}

## Principal Component Analysis

```{r echo = FALSE, fig.width=10, fig.height=7}
# p1 <- pca_func(data=t(tit.all_num[,2:ncol(tit.all_num)]), groups = as.character(tit.all_num$Survived), title="Survival on The Titanic", print_ellipse = TRUE)
  
p1 <- pca_func(t(glass[,1:(ncol(glass)-1)]), groups=as.character(glass$Type), title = "Glass Samples: PCA", print_ellipse=TRUE)
p2 <- pca_func(data = glass[,1:(ncol(glass)-1)], groups = as.character(colnames(glass[,1:(ncol(glass)-1)])), title = "Glass Feature Importance", print_ellipse = FALSE)
main=textGrob("Principal Component Analysis of Glass",gp=gpar(fontsize=20,font=3))
grid.arrange(p1, p2, ncol = 2, top = main)
```

This is the result of PCA Clustering, not really the clearest result as far as grouping goes, but we can see that with respect to the Features, Calcium (Ca) and Silicon (Si) weigh in heavy as strong factors. However, it doesn't look like it clusters very well, so we'll move on.

***

## Boruta 

{r echo=FALSE}
tb <- Boruta(train[,-10],
       train$Type,
       maxRuns=101,
       doTrace=0)
plot(tb)


With Respect to Boruta, all the elements seem to be significant, with Magnesium (Mg) being the element with the most Importance.

{r echo = FALSE}
data <- sample(2, nrow(glass), replace = T, prob = c(0.7, 0.3))
train <- glass[data == 1,]
test <- glass[data == 2,]


***

## Neural Network{.tabset}

### Processing

{r echo = FALSE}
set.seed(1414)
start <- proc.time()[3]
model.nn <- caret::train(Type ~ .,
                         data = train,
                         method = "nnet",
                         verbose = FALSE)
print(model.nn)
predictions <- predict(model.nn, test[,1:9])
accuracy <- sum(predictions == test[,10])/length(test[,10])
accuracy <- signif(accuracy*100,4)
print(accuracy)
end <- proc.time()[3]


{r echo = FALSE}
caret::varImp(model.nn) 




With Neural Networks, we recieved an accuracy of __`r accuracy`%__ and it took __`r end`__ seconds.

{r echo = FALSE}
set.seed(1414)
start <- proc.time()[3]
model.nn <- caret::train(Type ~ .  - RI,
                         data = train,
                         method = "nnet",
                         verbose = FALSE)
print(model.nn)
predictions <- predict(model.nn, test[,1:9])
accuracy_nn2 <- sum(predictions == test[,10])/length(test[,10])
accuracy_nn2 <- signif(accuracy_nn2*100,4)
print(accuracy_nn2)
end <- proc.time()[3]
acc_diff_nn <- accuracy_nn2 - accuracy


With Cutting out RI as a variable, our new Neural Network accuracy is __`r accuracy_nn2`%__, which improved/decreased the accuracy of the model with all the variable by __`r acc_diff_nn`%__ and it took __`r end` seconds__.

### Neural Network Visualization 

{r fig.width=10, fig.height=8}
plotnet(model.nn$finalModel, y_names = "Type")


***

## Elastic Net

{r echo = FALSE, message=FALSE, warning = FALSE}

data <- sample(2, nrow(glass), replace = T, prob = c(0.7, 0.3))
train <- glass[data == 1,]
test <- glass[data == 2,]

start <- proc.time()[3]

myTrainControl <- trainControl(method="repeatedcv",number=10,repeats = 4)


fit.glmnet <- train(Type~. ,train,trControl = myTrainControl,
                    method="glmnet",tuneGrid=expand.grid(.alpha = seq(0,1,by=0.05), 
                                                         .lambda = seq(0, 0.08, by = 0.01)))
plot(fit.glmnet)

predictions <- predict(fit.glmnet, test[,1:9])
accuracy_glmnet <- confusionMatrix(test$Type, predictions)
accuracy_glmnet
end <- proc.time()[3]


```

With Elastic Netting and using all variables, we get an accuracy of __`r signif(accuracy_glmnet$overall[[1]]*100,4)`%__.

{r echo = FALSE}
caret::varImp(fit.glmnet)

***

## cTree

{r echo = FALSE}
glass_c_tree <- ctree(Type ~ ., data=train)
prediction_c_tree = predict(glass_c_tree, test)
ctree_cm <- confusionMatrix(test$Type,prediction_c_tree)
ctree_cm
predacc_c_tree <- signif(ctree_cm$overall[[1]]*100,4)

With a Classification Tree, we still have a measily __`r predacc_c_tree`%__, let's work towards better results.


## Random Forest
{r echo = FALSE}

data <- sample(2, nrow(glass), replace = T, prob = c(0.7, 0.3))
train <- glass[data == 1,]
test <- glass[data == 2,]

# prepare training scheme
control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

set.seed(27)
imp_1 <- train(Type ~ .,
               data = train,
               method = "rf",
               preProcess = c("scale", "center"),
               trControl = control)
p1 <- feature_imp(imp_1, title = "Glass Classification")
p1


It looks like we have pretty good feature importance with respect to random forest (or atleast the graph comes out nice)

```{r echo = FALSE}



rf_pred <- predict(imp_1, newdata=test, type='raw')
rf_cfm <- caret::confusionMatrix(test$Type, rf_pred)
rf_cfm
```

With Random Forest, we get an accuracy of __`r signif(rf_cfm$overall[[1]]*100,4)`%__, which is okay, but nothing really to write home about.

***

## C5 Bagging CART

{r echo = FALSE}
x = test[,1:ncol(test)-1]
y = test[,ncol(test)]


model <- bagging(Type ~ . , data=train) 
pred <- predict(model,x) 
l <- union(pred,y)
mtab <- table(factor(pred,l),factor(y,l))
cfm_CART <- confusionMatrix(mtab)
cfm_CART

With a Treebag or "C5 Bagged CART", we recieve an accuracy of __`r signif(cfm_CART$overall[[1]]*100,4)`%__. Not too bad.

{r echo=FALSE, eval=FALSE, include=FALSE}

testValues <- test$Type

pred <- predict(model,newdata=x, type='prob')

predROC <- ROCR::prediction(pred,
                      testValues)

perfROC <- performance(predROC, 
                       measure = 'tpr', 
                       x.measure = 'fpr')


plot(perfROC, lwd = 2, colorize = TRUE) # rainbow!
lines(x = c(0, 1), y = c(0, 1), col = "black", lwd = 1)


auc = performance(predROC, measure = "auc")
auc = auc@y.values[[1]] %>% print


## Naive Bayes Prediction With Multiple ROC Chart

{r echo=FALSE, message=FALSE, warning=FALSE}
library(klaR)
glass_temp <- cbind(glass[,1:5], glass[,7], glass[,10])
glass_temp %<>% tbl_df()
colnames(glass_temp)[6] <- "Ca"
colnames(glass_temp)[7] <- "Type"

lvls = levels(glass_temp$Type)
# testidx = which(1:length(glass_temp[, 1]) %% 5 == 0) 
# glass.train = glass_temp[testidx, ]
# glass.test = glass_temp[-testidx, ]

dat <- sample(2, nrow(glass_temp), replace = T, prob = c(0.7, 0.3))
glass.train <- glass_temp[dat == 1,]
glass.test <- glass_temp[dat == 2,]

aucs = c()
plot(x=NA, y=NA, xlim=c(0,1), ylim=c(0,1),
     ylab='True Positive Rate',
     xlab='False Positive Rate',
     main='Naive Bayes Prediction For Glass Types: AUC/ROC',
     bty='n')

for (type.id in 1:6) {
  type = as.factor(glass.train$Type == lvls[type.id])

  nbmodel = NaiveBayes(type ~ ., data=glass.train[, -7])
  nbprediction = predict(nbmodel, glass.test[,-7], type='raw')

  score = nbprediction$posterior[, 'TRUE']
  actual.class = glass.test$Type == lvls[type.id]

  pred = prediction(score, actual.class)
  nbperf = performance(pred, "tpr", "fpr")

  roc.x = unlist(nbperf@x.values)
  roc.y = unlist(nbperf@y.values)
  lines(roc.y ~ roc.x, col=type.id+1, lwd=2)

  nbauc = performance(pred, "auc")
  nbauc = unlist(slot(nbauc, "y.values"))
  aucs[type.id] = nbauc
}

lines(x=c(0,1), c(0,1))
legend("bottomright", c("Glass Type: 1", "Glass Type: 2", "Glass Type: 3", "Glass Type: 5", "Glass Type: 6", "Glass Type: 7"), lty=1,col=c("red", "green3", "blue", "cyan", "magenta", "yellow"), title="ROC Glass Types")




auc_tbl <- tbl_df(aucs)
auc_tbl[7,] <- mean(aucs)
auc_tbl$Glass_Type <- c("1","2","3","5","6","7", "Mean")
auc_tbl <- cbind(auc_tbl[,2], auc_tbl[,1])
auc_tbl %<>% tbl_df()
colnames(auc_tbl) <- c("Glass Type", "AUC")


With a Naive Bayes Prediction, we recieved an average AUC of __`r mean(aucs)`__.

Here is the full table
{r echo=FALSE}
auc_tbl %>% kable()


{r echo = FALSE}
auc_tbl %<>% arrange(desc(AUC)) 


Our Lowest AUC with respect to our Naive Bayes Model belonged to __Glass Type: `r auc_tbl[7,1]`__ with an AUC of __`r auc_tbl[7,2]`__.
<br>
Our Highest AUC with respect to our Naive Bayes belonged to __Glass Type `r auc_tbl[1,1]`__ with an AUC of __`r auc_tbl[1,2]`__.
<br>
<br>
